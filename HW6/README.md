# HW6
## 使用 AI 說明本作業部分內容使用 ChatGPT 協助理解與撰寫，  
對話紀錄網址如下：[AI網址](https://chatgpt.com/share/6956c852-2710-8006-93c7-9c8b22d42cc4)
### 一、爬山演算法（Hill Climbing）
優點

- 實作簡單，程式碼短且容易理解
- 計算速度快，適合解決簡單或小型問題
- 不需要事先知道整個搜尋空間的結構

缺點

- 容易卡在「局部最佳解」，無法找到全域最佳解
- 結果高度依賴初始解，起點不好就會得到差的結果
- 無法處理有很多高低起伏的複雜問題
### 我的理解: 
有可能卡在局部最佳解，而無法到達真正最高點。

二、貪婪法（Greedy Algorithm）
優點

- 每一步只做局部最佳選擇，執行效率高
- 實作容易，適合即時或資源有限的情況
- 在某些特定問題中（如最小生成樹、最短路徑）可以得到最佳解

缺點

- 不保證一定能得到全域最佳解
- 只看眼前，不考慮長遠影響
- 對問題條件限制較多，不是所有問題都適用
### 我的理解: 
可以快速得到不錯的結果，
但不一定是整體最佳解。

三、梯度下降法（Gradient Descent）
優點

- 適合處理連續型、可微分的最佳化問題
- 在機器學習與數值最佳化中非常有效
- 每次更新方向明確，收斂速度通常快

缺點

- 需要選擇合適的學習率（learning rate）
- 學習率太大可能震盪或發散，太小則收斂很慢
- 同樣可能陷入局部最佳解或鞍點
- 只能用在可計算梯度的函數上
### 我的理解: 
也是一種貪婪策略，
因為每一步都選擇讓誤差下降最多的方向。

五、改良法（Improved Methods）
（例如：隨機重啟、模擬退火、Momentum）

優點

- 能降低卡在局部最佳解的機率
- 搜尋結果通常比原始方法穩定
- 適合處理複雜或多峰問題

缺點

- 計算成本較高，執行時間增加
- 參數設定較多，實作複雜度提高
- 不一定保證每次都能找到最佳解
### 我的理解: 
避免卡在壞的起點，
或讓搜尋過程更穩定、更有效率。
